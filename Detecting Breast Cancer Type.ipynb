{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5883fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from termcolor import colored \n",
    "from sklearn.svm import LinearSVC\n",
    "#Splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Hyperparameter tuning using GridSearchCV for SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6c74cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Hs.2256</th>\n",
       "      <th>Hs.346950</th>\n",
       "      <th>Hs.256697</th>\n",
       "      <th>Hs.434053</th>\n",
       "      <th>Hs.194726</th>\n",
       "      <th>Hs.74624</th>\n",
       "      <th>Hs.1578</th>\n",
       "      <th>Hs.30743</th>\n",
       "      <th>...</th>\n",
       "      <th>Hs.118962</th>\n",
       "      <th>Hs.250822</th>\n",
       "      <th>Hs.82563</th>\n",
       "      <th>Hs.418533</th>\n",
       "      <th>Hs.433416</th>\n",
       "      <th>Hs.436348</th>\n",
       "      <th>Hs.388664</th>\n",
       "      <th>Hs.302690</th>\n",
       "      <th>Hs.293885</th>\n",
       "      <th>Hs.82109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sample 115</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>0.197</td>\n",
       "      <td>3.433</td>\n",
       "      <td>2.044</td>\n",
       "      <td>-1.421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-1.259</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-1.170</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exp21630</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.482</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.727</td>\n",
       "      <td>0.033</td>\n",
       "      <td>1.103</td>\n",
       "      <td>1.782</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.215</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-1.038</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exp21626</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.796</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>3.006</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>0.488</td>\n",
       "      <td>1.429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>2.760</td>\n",
       "      <td>1.447</td>\n",
       "      <td>-0.712</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-1.313</td>\n",
       "      <td>-1.117</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exp21611</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.011</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>1.019</td>\n",
       "      <td>6.353</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sample 39 &gt;5 yr survival(132 months) age 46  e...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.437</td>\n",
       "      <td>3.585</td>\n",
       "      <td>-1.209</td>\n",
       "      <td>0.448</td>\n",
       "      <td>2.649</td>\n",
       "      <td>3.110</td>\n",
       "      <td>-0.695</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.963</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>-1.383</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>BC120A-BE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.656</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-3.591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.990</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1.840</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-1.300</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Sample 60  &lt;5 yr survival(59 months) age 45  e...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>4.908</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.355</td>\n",
       "      <td>-0.878</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>-2.076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>BC213B-BE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-2.193</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>0.228</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>-1.059</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-2.844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>0.796</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>-0.581</td>\n",
       "      <td>0.344</td>\n",
       "      <td>2.407</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>1.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Sample 22 &gt;5 yr survival(106 months) age 45  e...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>1.419</td>\n",
       "      <td>-1.024</td>\n",
       "      <td>-0.604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.719</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>BC/FUMI41-BE</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.105</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-1.265</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1.709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>2.073</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>0.499</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-2.527</td>\n",
       "      <td>1.290</td>\n",
       "      <td>-0.997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  CLID  Class  Hs.2256  \\\n",
       "0                                           Sample 115      0   -0.227   \n",
       "1                                             Exp21630      0   -1.482   \n",
       "2                                             Exp21626      0   -1.796   \n",
       "3                                             Exp21611      0   -3.011   \n",
       "4    Sample 39 >5 yr survival(132 months) age 46  e...      0   -0.437   \n",
       "..                                                 ...    ...      ...   \n",
       "244                                          BC120A-BE      4    0.656   \n",
       "245  Sample 60  <5 yr survival(59 months) age 45  e...      4   -0.505   \n",
       "246                                          BC213B-BE      4    0.377   \n",
       "247  Sample 22 >5 yr survival(106 months) age 45  e...      4   -0.088   \n",
       "248                                       BC/FUMI41-BE      4   -4.105   \n",
       "\n",
       "     Hs.346950  Hs.256697  Hs.434053  Hs.194726  Hs.74624  Hs.1578  Hs.30743  \\\n",
       "0        0.093      0.330     -0.672      0.197     3.433    2.044    -1.421   \n",
       "1        0.326      0.112     -0.649     -0.727     0.033    1.103     1.782   \n",
       "2       -0.346      3.006     -0.195      0.213    -0.628    0.488     1.429   \n",
       "3       -0.373     -0.161      1.019      6.353     0.147    0.330    -0.838   \n",
       "4        3.585     -1.209      0.448      2.649     3.110   -0.695    -0.987   \n",
       "..         ...        ...        ...        ...       ...      ...       ...   \n",
       "244      5.500      0.139     -0.961     -0.111    -0.113    0.090    -3.591   \n",
       "245      4.908      0.505      0.355     -0.878    -0.539   -0.592    -2.076   \n",
       "246     -2.193     -0.475      0.228     -0.415    -1.059   -0.520    -2.844   \n",
       "247      0.063      0.234      0.196     -0.194     1.419   -1.024    -0.604   \n",
       "248     -0.092     -1.265     -0.956     -0.418    -0.056    0.289     1.709   \n",
       "\n",
       "     ...  Hs.118962  Hs.250822  Hs.82563  Hs.418533  Hs.433416  Hs.436348  \\\n",
       "0    ...     -0.813      3.024     0.272     -0.751     -1.259      0.240   \n",
       "1    ...     -1.215      0.379     0.376     -0.845     -0.611     -0.270   \n",
       "2    ...     -0.069      2.760     1.447     -0.712      0.564      0.730   \n",
       "3    ...     -0.071     -0.056    -0.855     -0.356     -0.313      0.306   \n",
       "4    ...     -0.682      0.129     0.683     -0.311      0.383      0.963   \n",
       "..   ...        ...        ...       ...        ...        ...        ...   \n",
       "244  ...      0.414      1.078     1.990      0.581      1.840      0.733   \n",
       "245  ...     -0.607      0.285    -0.324      0.531     -0.413      0.459   \n",
       "246  ...     -0.006     -1.010     0.796     -0.465     -0.723     -0.581   \n",
       "247  ...      0.094     -1.571     0.302     -0.539     -0.326     -0.460   \n",
       "248  ...      0.308      0.281    -0.673      2.073     -0.556      0.499   \n",
       "\n",
       "     Hs.388664  Hs.302690  Hs.293885  Hs.82109  \n",
       "0       -1.170     -0.070     -0.164    -0.680  \n",
       "1       -1.038     -0.830      0.065    -0.711  \n",
       "2       -0.394     -1.313     -1.117     0.428  \n",
       "3        0.178      0.083     -0.409    -0.167  \n",
       "4       -0.848     -1.383      0.193     0.592  \n",
       "..         ...        ...        ...       ...  \n",
       "244     -0.292     -1.300      0.518    -0.701  \n",
       "245     -0.360     -0.078     -0.164     0.749  \n",
       "246      0.344      2.407     -0.167     1.042  \n",
       "247      0.223      0.719     -0.828     0.052  \n",
       "248     -0.529     -2.527      1.290    -0.997  \n",
       "\n",
       "[249 rows x 308 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= pd.read_csv(\"breast_cancer_genomic.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b512761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y with features and ground truth\n",
    "X = dataset.drop(columns=[\"Class\",\"CLID\"])\n",
    "y = dataset[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a9e4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split the data into training data and test data (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdc837ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our model and fit it to our training data\n",
    "clf = SVC(kernel='linear',C=1) # default values for kernel and C \n",
    "clf.fit(X_train, y_train) \n",
    "# make predictions on test data\n",
    "predicted = clf.predict(X_test)\n",
    "target_names = ['Luminal B','Luminal A','Normal-like','Basal-like','HER2+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc1fa7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mconfusion matrix:\n",
      "\u001b[0m [[ 6  1  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  1 13  1]\n",
      " [ 0  0  0  0  6]]\n",
      "\u001b[34m\n",
      "accuracy:\u001b[0m 0.94\n",
      "\u001b[32m\n",
      "classification report:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "   Luminal B       1.00      0.86      0.92         7\n",
      "   Luminal A       0.95      1.00      0.98        20\n",
      " Normal-like       0.67      1.00      0.80         2\n",
      "  Basal-like       1.00      0.87      0.93        15\n",
      "       HER2+       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.90      0.94      0.91        50\n",
      "weighted avg       0.95      0.94      0.94        50\n",
      "\n",
      "\u001b[31m\n",
      "Accuracy per class:\u001b[0m [0.85714286 1.         1.         0.86666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix. \n",
    "# **Note** since the ground truth is not binary (has 3 labels), the confusion matrix is a 3x3 matrix\n",
    "print(colored('confusion matrix:\\n', 'green'), metrics.confusion_matrix(y_test, predicted))\n",
    "\n",
    "# print classifier accuracy\n",
    "print(colored('\\naccuracy:', 'blue'), metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "# print classification report (Precision, reall, and F1 score for each label, and average)\n",
    "print(colored('\\nclassification report:\\n', 'green'),metrics.classification_report(y_test, predicted,target_names = target_names))\n",
    "\n",
    "# print Accuracy per class\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "#Now the normalize the diagonal entries\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#The diagonal entries are the accuracies of each class\n",
    "print(colored('\\nAccuracy per class:', 'red'),cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd89d23",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb3ea742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Best parameters:\u001b[0m {'C': 1, 'kernel': 'linear'} \n",
      "\n",
      "\u001b[32m\n",
      "accuracy:\u001b[0m 0.94\n",
      "\u001b[32m\n",
      "classification report:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "   Luminal B       1.00      0.86      0.92         7\n",
      "   Luminal A       0.95      1.00      0.98        20\n",
      " Normal-like       0.67      1.00      0.80         2\n",
      "  Basal-like       1.00      0.87      0.93        15\n",
      "       HER2+       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.90      0.94      0.91        50\n",
      "weighted avg       0.95      0.94      0.94        50\n",
      "\n",
      "\u001b[32mconfusion matrix:\n",
      "\u001b[0m [[ 6  1  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  1 13  1]\n",
      " [ 0  0  0  0  6]]\n",
      "\u001b[31m\n",
      "Accuracy per class:\u001b[0m [0.85714286 1.         1.         0.86666667 1.        ]\n",
      "\u001b[32m\n",
      "Best parameters:\u001b[0m {'C': 5, 'kernel': 'poly'} \n",
      "\n",
      "\u001b[32m\n",
      "accuracy:\u001b[0m 0.78\n",
      "\u001b[32m\n",
      "classification report:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "   Luminal B       0.75      0.43      0.55         7\n",
      "   Luminal A       0.67      1.00      0.80        20\n",
      " Normal-like       0.00      0.00      0.00         2\n",
      "  Basal-like       1.00      0.93      0.97        15\n",
      "       HER2+       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.68      0.54      0.56        50\n",
      "weighted avg       0.79      0.78      0.75        50\n",
      "\n",
      "\u001b[32mconfusion matrix:\n",
      "\u001b[0m [[ 3  4  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0  1  0 14  0]\n",
      " [ 1  3  0  0  2]]\n",
      "\u001b[31m\n",
      "Accuracy per class:\u001b[0m [0.42857143 1.         0.         0.93333333 0.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Evaluate each tuned model by averaging 10 runs of stratified 10-fold cross-validation.\n",
    "#Capture overall accuracy plus accuracy, precision, and recall by cancer type.\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly'),'C':[1, 5, 10]}\n",
    "model_parameters = {\n",
    "    'par1': {\n",
    "        'kernel' : ['linear'], \n",
    "         'C':[1, 5, 10]\n",
    "    },\n",
    "    'par2': {\n",
    "        'kernel':['rbf'],\n",
    "         'C':[1, 5, 10]\n",
    "    },\n",
    "    'par2': {\n",
    "        'kernel':['poly'],\n",
    "         'C':[1, 5, 10]\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "cv = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "for model_name, parameters in model_parameters.items():\n",
    "    \n",
    "    clf = GridSearchCV(svc, parameters, cv=cv,n_jobs=-1) # n_jobs -> number of parallel jobs\n",
    "                                                   # -1 -> whatever the architecture allows\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(colored('\\nBest parameters:', 'green'), clf.best_params_,\"\\n\") # print best parameters\n",
    "\n",
    "    # make predictions on test data\n",
    "    predicted = clf.predict(X_test)\n",
    "\n",
    "    # print accuracy\n",
    "    print(colored('\\naccuracy:', 'green'), metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "    # print precision and recall statistics\n",
    "    print(colored('\\nclassification report:\\n', 'green'),metrics.classification_report(y_test, predicted,target_names = target_names))\n",
    "\n",
    "    # print confusion matrix\n",
    "    print(colored('confusion matrix:\\n', 'green'),metrics.confusion_matrix(y_test, predicted))\n",
    "    \n",
    "    # print Accuracy per class\n",
    "    cm = metrics.confusion_matrix(y_test, predicted)\n",
    "    #Now the normalize the diagonal entries\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #The diagonal entries are the accuracies of each class\n",
    "    print(colored('\\nAccuracy per class:', 'red'),cm.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8715049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20918367 0.23469388 0.35672515 0.35672515 0.59064327 0.21052632\n",
      " 0.61988304 0.61988304 0.41520468 0.18970588]\n",
      "Mean:  0.38031740766482025\n",
      "Standard deviation:  0.1664347929133342\n"
     ]
    }
   ],
   "source": [
    "# get r2 cross validation scores\n",
    "#SVC\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='r2')\n",
    "    \n",
    "print(scores)\n",
    "print('Mean: ', np.mean(scores)) \n",
    "print('Standard deviation: ', np.std(scores))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1828997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9744898  1.         0.97076023 0.97076023 1.         0.70760234\n",
      " 0.94152047 0.9122807  0.94152047 0.97205882]\n",
      "Mean:  0.9390993063892225\n",
      "Standard deviation:  0.08129159955019517\n"
     ]
    }
   ],
   "source": [
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Fit our data\n",
    "Fit = model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "# get r2 cross validation scores\n",
    "scores = cross_val_score(model, X_train, y_train, cv=10, scoring='r2')\n",
    "    \n",
    "print(scores)\n",
    "print('Mean: ', np.mean(scores)) \n",
    "print('Standard deviation: ', np.std(scores))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8afe14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mconfusion matrix:\n",
      "\u001b[0m [[ 6  1  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  1 14  0]\n",
      " [ 0  0  0  0  6]]\n",
      "\u001b[34m\n",
      "accuracy:\u001b[0m 0.96\n",
      "\u001b[32m\n",
      "classification report:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "   Luminal B       1.00      0.86      0.92         7\n",
      "   Luminal A       0.95      1.00      0.98        20\n",
      " Normal-like       0.67      1.00      0.80         2\n",
      "  Basal-like       1.00      0.93      0.97        15\n",
      "       HER2+       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.92      0.96      0.93        50\n",
      "weighted avg       0.97      0.96      0.96        50\n",
      "\n",
      "\u001b[31m\n",
      "Accuracy per class:\u001b[0m [0.85714286 1.         1.         0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Confusion matrix for MLR\n",
    "print(colored('confusion matrix:\\n', 'green'), metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print classifier accuracy\n",
    "print(colored('\\naccuracy:', 'blue'), metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print classification report (Precision, reall, and F1 score for each label, and average)\n",
    "print(colored('\\nclassification report:\\n', 'green'),metrics.classification_report(y_test, y_pred,target_names = target_names))\n",
    "\n",
    "# print Accuracy per class\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "#Now the normalize the diagonal entries\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#The diagonal entries are the accuracies of each class\n",
    "print(colored('\\nAccuracy per class:', 'red'),cm.diagonal())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b99324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1834736  0.13684981 0.57944082 0.7303196  0.07983139 0.27748869\n",
      " 0.46209443 0.5869003  0.4343926  0.25984838]\n",
      "Mean:  0.37306396211852605\n",
      "Standard deviation:  0.20671622503401277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Train model with default alpha=1\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# get cross val scores\n",
    "scores = cross_val_score(ridge, X_train, y_train, cv=10, scoring='r2')\n",
    "\n",
    "print(scores)\n",
    "print('Mean: ', np.mean(scores)) \n",
    "print('Standard deviation: ', np.std(scores))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac189881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.342128</td>\n",
       "      <td>0.543406</td>\n",
       "      <td>0.428053</td>\n",
       "      <td>0.494664</td>\n",
       "      <td>0.469967</td>\n",
       "      <td>0.455644</td>\n",
       "      <td>0.067937</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>0.544429</td>\n",
       "      <td>0.428883</td>\n",
       "      <td>0.495679</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.456516</td>\n",
       "      <td>0.067914</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.344505</td>\n",
       "      <td>0.545697</td>\n",
       "      <td>0.429912</td>\n",
       "      <td>0.496937</td>\n",
       "      <td>0.470938</td>\n",
       "      <td>0.457598</td>\n",
       "      <td>0.067887</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.366015</td>\n",
       "      <td>0.566513</td>\n",
       "      <td>0.447131</td>\n",
       "      <td>0.517735</td>\n",
       "      <td>0.479994</td>\n",
       "      <td>0.475478</td>\n",
       "      <td>0.067645</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>0.430343</td>\n",
       "      <td>0.630018</td>\n",
       "      <td>0.502988</td>\n",
       "      <td>0.581925</td>\n",
       "      <td>0.510585</td>\n",
       "      <td>0.531172</td>\n",
       "      <td>0.068893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.016177      0.003931         0.011055        0.002750        0.01   \n",
       "1       0.011992      0.001842         0.008513        0.001304        0.05   \n",
       "2       0.009827      0.000887         0.008288        0.001516         0.1   \n",
       "3       0.009444      0.000836         0.006438        0.000582           1   \n",
       "4       0.008444      0.001462         0.004949        0.001126           5   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.01}           0.342128           0.543406           0.428053   \n",
       "1  {'alpha': 0.05}           0.343190           0.544429           0.428883   \n",
       "2   {'alpha': 0.1}           0.344505           0.545697           0.429912   \n",
       "3     {'alpha': 1}           0.366015           0.566513           0.447131   \n",
       "4     {'alpha': 5}           0.430343           0.630018           0.502988   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.494664           0.469967         0.455644        0.067937   \n",
       "1           0.495679           0.470400         0.456516        0.067914   \n",
       "2           0.496937           0.470938         0.457598        0.067887   \n",
       "3           0.517735           0.479994         0.475478        0.067645   \n",
       "4           0.581925           0.510585         0.531172        0.068893   \n",
       "\n",
       "   rank_test_score  \n",
       "0                5  \n",
       "1                4  \n",
       "2                3  \n",
       "3                2  \n",
       "4                1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=ridge, param_grid={'alpha':[0.01, 0.05, 0.1, 1, 5]}, scoring='r2', n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Now import the results into a dataframe \n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c630f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.455644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.456516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.457598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.475478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.531172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_alpha  mean_test_score\n",
       "0        0.01         0.455644\n",
       "1        0.05         0.456516\n",
       "2         0.1         0.457598\n",
       "3           1         0.475478\n",
       "4           5         0.531172"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['param_alpha', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3607911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.5311718672186765\n",
      "Best Params:  {'alpha': 5}\n"
     ]
    }
   ],
   "source": [
    "#Find the best score and the best parameter (alpha value)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "810b4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37606745 0.21609544 0.44678675 0.34438138 0.47402472 0.19697579\n",
      " 0.31608458 0.47392758 0.15907405 0.4562517 ]\n",
      "Mean:  0.3459669447526167\n",
      "Standard deviation:  0.11440957771593507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Train model with default alpha=1\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# get cross val scores\n",
    "scores = cross_val_score(lasso, X_train, y_train, cv=10, scoring='r2')\n",
    "\n",
    "print(scores)\n",
    "print('Mean: ', np.mean(scores)) \n",
    "print('Standard deviation: ', np.std(scores))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d19c2aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=7.28518e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, sym_pos=True,\n",
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=7.37839e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, sym_pos=True,\n",
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=7.50173e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, sym_pos=True,\n",
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=6.72691e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, sym_pos=True,\n",
      "/Users/mohammedalturki/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:187: LinAlgWarning: Ill-conditioned matrix (rcond=8.08144e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7147965236896334\n",
      "Best Params:  {'alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=ridge, param_grid={'alpha':[1e-12, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 0.1, 1, 5, 10, 20, 50, 100, 500, 1000]}, scoring='r2', n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2715b7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.455427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.455446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.455644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.457598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.475478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.531172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.573331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>0.621804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>0.682185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>0.714797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>500</td>\n",
       "      <td>0.712177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.668663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_alpha  mean_test_score\n",
       "0          0.0         0.455424\n",
       "1          0.0         0.455424\n",
       "2          0.0         0.455424\n",
       "3       0.0001         0.455427\n",
       "4        0.001         0.455446\n",
       "5         0.01         0.455644\n",
       "6          0.1         0.457598\n",
       "7            1         0.475478\n",
       "8            5         0.531172\n",
       "9           10         0.573331\n",
       "10          20         0.621804\n",
       "11          50         0.682185\n",
       "12         100         0.714797\n",
       "13         500         0.712177\n",
       "14        1000         0.668663"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['param_alpha', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0191da",
   "metadata": {},
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aab1a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mconfusion matrix:\n",
      "\u001b[0m [[ 6  1  0  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  1 14  0]\n",
      " [ 0  0  0  0  6]]\n",
      "\u001b[34m\n",
      "accuracy:\u001b[0m 0.96\n",
      "\u001b[32m\n",
      "classification report:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "   Luminal B       1.00      0.86      0.92         7\n",
      "   Luminal A       0.95      1.00      0.98        20\n",
      " Normal-like       0.67      1.00      0.80         2\n",
      "  Basal-like       1.00      0.93      0.97        15\n",
      "       HER2+       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.92      0.96      0.93        50\n",
      "weighted avg       0.97      0.96      0.96        50\n",
      "\n",
      "\u001b[31m\n",
      "Accuracy per class:\u001b[0m [0.85714286 1.         1.         0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix for MLR\n",
    "print(colored('confusion matrix:\\n', 'green'), metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print classifier accuracy\n",
    "print(colored('\\naccuracy:', 'blue'), metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print classification report (Precision, reall, and F1 score for each label, and average)\n",
    "print(colored('\\nclassification report:\\n', 'green'),metrics.classification_report(y_test, y_pred,target_names = target_names))\n",
    "\n",
    "# print Accuracy per class\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "#Now the normalize the diagonal entries\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#The diagonal entries are the accuracies of each class\n",
    "print(colored('\\nAccuracy per class:', 'red'),cm.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01fd064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model for Decision Tree\n",
    "par = {'criterion' : ['gini'], 'random_state':[249], 'max_depth' : [None], 'min_samples_leaf':[1]}\n",
    "#model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f30fef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [None],\n",
       "                         'min_samples_leaf': [1], 'random_state': [249]})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(DecisionTreeClassifier(), par, cv=10)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92538826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mconfusion matrix:\n",
      "\u001b[0m [[ 3  3  0  0  1]\n",
      " [ 6 13  1  0  0]\n",
      " [ 0  1  1  0  0]\n",
      " [ 2  0  0 12  1]\n",
      " [ 0  0  0  2  4]]\n",
      "\u001b[34m\n",
      "accuracy:\u001b[0m 0.66\n",
      "\u001b[32m\n",
      "classification report:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "   Luminal B       0.27      0.43      0.33         7\n",
      "   Luminal A       0.76      0.65      0.70        20\n",
      " Normal-like       0.50      0.50      0.50         2\n",
      "  Basal-like       0.86      0.80      0.83        15\n",
      "       HER2+       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.61      0.61      0.61        50\n",
      "weighted avg       0.70      0.66      0.68        50\n",
      "\n",
      "\u001b[31m\n",
      "Accuracy per class:\u001b[0m [0.42857143 0.65       0.5        0.8        0.66666667]\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees Confusion Matrix\n",
    "y_predd = clf.predict(X_test)\n",
    "\n",
    "print(colored('confusion matrix:\\n', 'green'), metrics.confusion_matrix(y_test, y_predd))\n",
    "\n",
    "# print classifier accuracy\n",
    "print(colored('\\naccuracy:', 'blue'), metrics.accuracy_score(y_test, y_predd))\n",
    "\n",
    "# print classification report (Precision, reall, and F1 score for each label, and average)\n",
    "print(colored('\\nclassification report:\\n', 'green'),metrics.classification_report(y_test, y_predd,target_names = target_names))\n",
    "\n",
    "# print Accuracy per class\n",
    "cm = metrics.confusion_matrix(y_test, y_predd)\n",
    "#Now the normalize the diagonal entries\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#The diagonal entries are the accuracies of each class\n",
    "print(colored('\\nAccuracy per class:', 'red'),cm.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c3bc619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41326531 0.74489796 0.73684211 0.64912281 0.73684211 0.15204678\n",
      " 0.21052632 0.32748538 0.9122807  0.13382353]\n",
      "Mean:  0.5017132993548297\n",
      "Standard deviation:  0.272136523489935\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees Mean and Standard Deviation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='r2')\n",
    "    \n",
    "print(scores)\n",
    "print('Mean: ', np.mean(scores)) \n",
    "print('Standard deviation: ', np.std(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe0533f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree vs MultinomialLogisticRegression\n",
      "F statistic: -0.446\n",
      "p value: 0.657\n",
      "we accept null hypothesis\n"
     ]
    }
   ],
   "source": [
    "f, pval = stats.ttest_ind(y_predd,y_pred)\n",
    "print(\"Decision Tree vs MultinomialLogisticRegression\")\n",
    "print('F statistic: %.3f' % f)\n",
    "print('p value: %.3f' % pval)\n",
    "if pval <0.05:\n",
    "  print(\"we reject null hypothesis\")\n",
    "else:\n",
    "  print(\"we accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39c4342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR vs SVC\n",
      "F statistic: 1.080\n",
      "p value: 0.283\n",
      "we accept null hypothesis\n"
     ]
    }
   ],
   "source": [
    "f, pval = stats.ttest_ind(y_pred,predicted)\n",
    "print(\"MLR vs SVC\")\n",
    "print('F statistic: %.3f' % f)\n",
    "print('p value: %.3f' % pval)\n",
    "if pval <0.05:\n",
    "  print(\"we reject null hypothesis\")\n",
    "else:\n",
    "  print(\"we accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "266a19c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree vs SVC\n",
      "F statistic: 0.555\n",
      "p value: 0.580\n",
      "we accept null hypothesis\n"
     ]
    }
   ],
   "source": [
    "f, pval = stats.ttest_ind(y_predd,predicted)\n",
    "print(\"Decision Tree vs SVC\")\n",
    "print('F statistic: %.3f' % f)\n",
    "print('p value: %.3f' % pval)\n",
    "if pval <0.05:\n",
    "  print(\"we reject null hypothesis\")\n",
    "else:\n",
    "  print(\"we accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12bece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766314b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
